{"cells":[{"metadata":{},"id":"346f4308","cell_type":"markdown","source":"# Sentiment Analysis of Yelp Reviews - Modeling\n\n### Contents\n\n - Introduction\n - Part 1: Machine Learning with Extracted Features \n       - Logistic Regression\n       - Random Forest\n       - Support Vector Classification\n       - Results\n        \n- Part 2: Machine Learning with Bag of Words\n       - Naive Bayes with CountVectorizer\n       - Naive Bayes with TFIDF\n       - Results\n- Part 3: Embedding Techniques\n       - Dense + Sparse Features\n       - Naive Bayes Probability with Dense + Sparse Features\n       - Stacked Model\n       - Results\n- Conclusion\n\n### Introduction\n\nWe've collected the data, analyzed it, found the most important feautres, and have a baseline accuracy around 50%. Now we'll be going through some other methods of modeling to find the most accurate version.\n\nIn this notebook we will:\n\n- Test out multiple different models\n- Including Regular ML Models with our extracted features and embedded models with sparse/dense text matrices"},{"metadata":{"trusted":true},"id":"bf0757b5","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nyelp_data = pd.read_csv('https://raw.githubusercontent.com/rabin1323/DataScience_Final_Project/main/yelp_data_sentiment.csv')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"id":"1ec861df","cell_type":"code","source":"yelp_data.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"              business_id                                               text  \\\n0  dPxZI9lrKTl5dvFfnb1_Ig  Went in for the first time tonight and within ...   \n1  dPxZI9lrKTl5dvFfnb1_Ig  Hands down this is Las Vegas best mom and pop ...   \n2  dPxZI9lrKTl5dvFfnb1_Ig  The BEST & REAL ITALIAN Food in Las Vegas! So ...   \n3  dPxZI9lrKTl5dvFfnb1_Ig  Excellent family-run Italian restaurant. Off-s...   \n4  dPxZI9lrKTl5dvFfnb1_Ig  We went here to celebrate a birthday. The atmo...   \n\n   Polarity          Sentiment  Positive_Words_P  went  first  time  bread  \\\n0  0.404286           Positive          0.242105   0.0    0.0   0.0    0.0   \n1  0.116429  Slightly Negative          0.132075   0.0    0.0   0.0    0.0   \n2  0.450000           Positive          0.125000   0.0    0.0   0.0    0.0   \n3  0.179167  Slightly Negative          0.210526   0.0    0.0   0.0    0.0   \n4  0.617143           Positive          0.500000   0.0    0.0   0.0    0.0   \n\n      would  ...  super  return     quick    reason     steak  must      hous  \\\n0  0.000000  ...    0.0     0.0  0.000000  0.126339  0.000000   0.0  0.000000   \n1  0.179843  ...    0.0     0.0  0.167635  0.000000  0.000000   0.0  0.000000   \n2  0.000000  ...    0.0     0.0  0.000000  0.000000  0.000000   0.0  0.000000   \n3  0.000000  ...    0.0     0.0  0.206105  0.000000  0.000000   0.0  0.237339   \n4  0.000000  ...    0.0     0.0  0.000000  0.271624  0.348561   0.0  0.000000   \n\n       dine  care  realli good  \n0  0.104748   0.0          0.0  \n1  0.000000   0.0          0.0  \n2  0.000000   0.0          0.0  \n3  0.000000   0.0          0.0  \n4  0.000000   0.0          0.0  \n\n[5 rows x 255 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_id</th>\n      <th>text</th>\n      <th>Polarity</th>\n      <th>Sentiment</th>\n      <th>Positive_Words_P</th>\n      <th>went</th>\n      <th>first</th>\n      <th>time</th>\n      <th>bread</th>\n      <th>would</th>\n      <th>...</th>\n      <th>super</th>\n      <th>return</th>\n      <th>quick</th>\n      <th>reason</th>\n      <th>steak</th>\n      <th>must</th>\n      <th>hous</th>\n      <th>dine</th>\n      <th>care</th>\n      <th>realli good</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>Went in for the first time tonight and within ...</td>\n      <td>0.404286</td>\n      <td>Positive</td>\n      <td>0.242105</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.126339</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.104748</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>Hands down this is Las Vegas best mom and pop ...</td>\n      <td>0.116429</td>\n      <td>Slightly Negative</td>\n      <td>0.132075</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.179843</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.167635</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>The BEST &amp; REAL ITALIAN Food in Las Vegas! So ...</td>\n      <td>0.450000</td>\n      <td>Positive</td>\n      <td>0.125000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>Excellent family-run Italian restaurant. Off-s...</td>\n      <td>0.179167</td>\n      <td>Slightly Negative</td>\n      <td>0.210526</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.206105</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.237339</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>We went here to celebrate a birthday. The atmo...</td>\n      <td>0.617143</td>\n      <td>Positive</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.271624</td>\n      <td>0.348561</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 255 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"id":"dac5375e","cell_type":"markdown","source":"## Part 1: Machine Learning with Extracted Features\nThere are many different models we can try but to start we're going to work with the standard machine learning models like logistic regression and random forest\n\nI'll be collecting accuracy and f1 scores along the way to see which model performs the best with this data!\n\nHere's what the process will look like:\n\n- Choose a model type\n- Define a pipeline and use GridSearch to find the best parameters\n- Save the model so we don't have the run the cell multiple times\n- Load the model and run accuracy and f1 scores\n- Move on to the next model\n\n"},{"metadata":{"trusted":true},"id":"c0f3007a","cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport pickle\nfrom pycm import *\n\nX = yelp_data.iloc[0:,4:]\ny = yelp_data.Sentiment\nindices = yelp_data.index\n\nX_train, X_test, y_train, y_test, itrain, itest = train_test_split(X,y,indices,train_size=0.8,random_state=7)","execution_count":3,"outputs":[]},{"metadata":{},"id":"f727b25a","cell_type":"markdown","source":"## Logistic Regression\nFor this model we're going to create a pipeline that uses the standard scaler and a classifier using GridSearch to find the best parameters"},{"metadata":{"trusted":true},"id":"0ba911bf","cell_type":"code","source":"steps = [('scaler', StandardScaler()), ('lr', LogisticRegression(solver = 'lbfgs'))] \npipeline = Pipeline(steps)\nparameters = {'lr__C':[0.01, 0.1, 1, 10, 100]}\n\nclf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\") \nclf.fit(X_train, y_train)\nclf.best_params_","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"{'lr__C': 0.1}"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"94ff61f0","cell_type":"code","source":"filename = 'lr.sav'\npickle.dump(clf, open(filename, 'wb'))","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"id":"aa35c879","cell_type":"code","source":"filename = 'lr.sav'\nclf = pickle.load(open(filename, 'rb'))","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"id":"7e895b7f","cell_type":"code","source":"results = clf.predict(X_test)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"id":"268535f3","cell_type":"code","source":"test_accuracy = clf.score(X_test, y_test)\nf1_accuracy = f1_score(y_test,results,average='macro')\nf1_accuracym = f1_score(y_test,results,average='micro')\nf1_accuracyw = f1_score(y_test,results,average='weighted')\nprint(\"Accuracy on test data: \" ,test_accuracy)\nprint('F1 Score (macro): ', f1_accuracy)\nprint('F1 Score (micro): ', f1_accuracym)\nprint('F1 Score (weighted): ', f1_accuracyw)","execution_count":8,"outputs":[{"output_type":"stream","text":"Accuracy on test data:  0.5841784989858012\nF1 Score (macro):  0.566725460237571\nF1 Score (micro):  0.5841784989858012\nF1 Score (weighted):  0.5821563361924262\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"98279c86","cell_type":"code","source":"lr_acc = test_accuracy\nlr_f1 = f1_accuracy\nlr_f1m = f1_accuracym\nlr_f1w = f1_accuracyw","execution_count":9,"outputs":[]},{"metadata":{},"id":"45bce696","cell_type":"markdown","source":"## Random Forest\n\nSame thing here, first we'll make a pipeline and then use gridsearch to find the best parameters to tune this model"},{"metadata":{"trusted":true},"id":"5cc10ed3","cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"id":"fa65b0a9","cell_type":"code","source":"steps = [('scaler', StandardScaler()), ('rf', RandomForestClassifier())] \npipeline = Pipeline(steps) \nparameters = {'rf__n_estimators':[10 , 20, 30, 40, 50], 'rf__max_features':['auto','sqrt']}\nclf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\") \nclf.fit(X_train, y_train)\n\nclf.best_params_","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"{'rf__max_features': 'sqrt', 'rf__n_estimators': 40}"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"11763c6f","cell_type":"code","source":"filename = 'rf.sav'\npickle.dump(clf, open(filename, 'wb'))","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"id":"15ea32d1","cell_type":"code","source":"filename = 'rf.sav'\nclf = pickle.load(open(filename, 'rb'))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"id":"1044109a","cell_type":"code","source":"results = clf.predict(X_test)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"id":"e2db0164","cell_type":"code","source":"test_accuracy = clf.score(X_test, y_test)\nf1_accuracy = f1_score(y_test,results,average='macro')\nf1_accuracym = f1_score(y_test,results,average='micro')\nf1_accuracyw = f1_score(y_test,results,average='weighted')\nprint(\"Accuracy on test data: \" ,test_accuracy)\nprint('F1 Score (macro): ', f1_accuracy)\nprint('F1 Score (micro): ', f1_accuracym)\nprint('F1 Score (weighted): ', f1_accuracyw)","execution_count":15,"outputs":[{"output_type":"stream","text":"Accuracy on test data:  0.5578093306288032\nF1 Score (macro):  0.5340313270771145\nF1 Score (micro):  0.5578093306288032\nF1 Score (weighted):  0.552939080661081\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"fa6faf9b","cell_type":"code","source":"rf_acc = test_accuracy\nrf_f1 = f1_accuracy\nrf_f1m = f1_accuracym\nrf_f1w = f1_accuracyw","execution_count":16,"outputs":[]},{"metadata":{},"id":"d6d425f2","cell_type":"markdown","source":"## Support Vector Classification (SVC)\n\nFor the SVC model I will unfortunately have to set the kernel to 'linear' and the gamma to 'auto'."},{"metadata":{"trusted":true},"id":"cec22a6a","cell_type":"code","source":"from sklearn.svm import SVC\n\nsteps = [('scaler', StandardScaler()), ('svc', SVC(probability=False,kernel='linear',gamma='auto'))] \npipeline = Pipeline(steps) \nparameters = {'svc__C':[0.01, 0.1, 1]}\n\nclf = GridSearchCV(pipeline, parameters, cv = 3, scoring=\"accuracy\") \nclf.fit(X_train, y_train)\n\nclf.best_params_","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"{'svc__C': 0.01}"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"4a5e80dc","cell_type":"code","source":"filename = 'svc.sav'\npickle.dump(clf, open(filename, 'wb'))","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"id":"0ca635bf","cell_type":"code","source":"filename = 'svc.sav'\nclf = pickle.load(open(filename, 'rb'))","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"id":"1fdf70ec","cell_type":"code","source":"results = clf.predict(X_test)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"id":"3508e15e","cell_type":"code","source":"test_accuracy = clf.score(X_test, y_test)\nf1_accuracy = f1_score(y_test,results,average='macro')\nf1_accuracym = f1_score(y_test,results,average='micro')\nf1_accuracyw = f1_score(y_test,results,average='weighted')\nprint(\"Accuracy on test data: \" ,test_accuracy)\nprint('F1 Score (macro): ', f1_accuracy)\nprint('F1 Score (micro): ', f1_accuracym)\nprint('F1 Score (weighted): ', f1_accuracyw)","execution_count":21,"outputs":[{"output_type":"stream","text":"Accuracy on test data:  0.5983772819472617\nF1 Score (macro):  0.5817718479006232\nF1 Score (micro):  0.5983772819472617\nF1 Score (weighted):  0.5957082762355302\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"1d518b37","cell_type":"code","source":"svc_acc = test_accuracy\nsvc_f1 = f1_accuracy\nsvc_f1m = f1_accuracym\nsvc_f1w = f1_accuracyw","execution_count":22,"outputs":[]},{"metadata":{},"id":"8c0b9060","cell_type":"markdown","source":"## Results\n\nNow we have all our scores, let's see which model performed the best"},{"metadata":{"trusted":true},"id":"77d95e85","cell_type":"code","source":"result1 = pd.DataFrame({'Model':['Logistic Regression', 'Random Forest', 'SVC'],\n             'Accuracy':[lr_acc, rf_acc, svc_acc],\n             'F1_Macro':[lr_f1, rf_f1, svc_f1],\n             'F1_Micro':[lr_f1m, rf_f1m, svc_f1m],\n             'F1_Weighted':[lr_f1w, rf_f1w, svc_f1w]})\nresult1 = result1.round(3)\nresult1","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"                 Model  Accuracy  F1_Macro  F1_Micro  F1_Weighted\n0  Logistic Regression     0.584     0.567     0.584        0.582\n1        Random Forest     0.558     0.534     0.558        0.553\n2                  SVC     0.598     0.582     0.598        0.596","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>F1_Macro</th>\n      <th>F1_Micro</th>\n      <th>F1_Weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>0.584</td>\n      <td>0.567</td>\n      <td>0.584</td>\n      <td>0.582</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest</td>\n      <td>0.558</td>\n      <td>0.534</td>\n      <td>0.558</td>\n      <td>0.553</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVC</td>\n      <td>0.598</td>\n      <td>0.582</td>\n      <td>0.598</td>\n      <td>0.596</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"id":"a271048d","cell_type":"markdown","source":"## Part 2: Machine Learning Models with Bag of Words\n\nThis time around we'll be working backwards, we've already done feature selection for our text, but with these methods we should be able to construct a dense/sparse text matrix and make an independent prediction based on just the text\n\nThe goal here is to find a purely text based model to generate a prediction, then to assign that prediciton to a new feature. This should significantly improve performance"},{"metadata":{"trusted":true},"id":"7e4d5f8d","cell_type":"code","source":"# new pure text based dataset\n\nX = yelp_data.text\ny = yelp_data.Sentiment\nindices = yelp_data.index","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"id":"b964eb0d","cell_type":"code","source":"# same split, size and random state\nX_train, X_test, y_train, y_test, i_train, i_test = train_test_split(X, y, indices, train_size = 0.8, random_state = 7)","execution_count":25,"outputs":[]},{"metadata":{},"id":"5b2d370a","cell_type":"markdown","source":"## Naive Bayes with CountVectorizer\n\nNow we're going to test two classification methods with two different text vectorizers to get the best result, first we'll do Naive Bayes with CV and TFIDF"},{"metadata":{"trusted":true},"id":"fca45f06","cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\n\nsteps = [('vec', CountVectorizer(stop_words = 'english', ngram_range = (1, 2))), ('nb', MultinomialNB())] \npipeline = Pipeline(steps) \nparameters = {'vec__min_df':[0.01, 0.1, 1, 10, 100], 'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n\nclf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\") \nclf.fit(X_train, y_train)\n\nclf.best_params_","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"{'nb__alpha': 1, 'vec__min_df': 10}"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"c4bc70fa","cell_type":"code","source":"filename = 'nb_cv.sav'\npickle.dump(clf, open(filename, 'wb'))","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"id":"49d10138","cell_type":"code","source":"filename = 'nb_cv.sav'\nclf = pickle.load(open(filename, 'rb'))","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"id":"6154c19f","cell_type":"code","source":"results = clf.predict(X_test)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"id":"81c04741","cell_type":"code","source":"test_accuracy = clf.score(X_test, y_test)\nprobs = clf.predict_proba(X_test)[:, 1]\nf1_accuracy = f1_score(y_test,results,average='macro')\nf1_accuracym = f1_score(y_test,results,average='micro')\nf1_accuracyw = f1_score(y_test,results,average='weighted')\nprint(\"Accuracy on test data: \" ,test_accuracy)\nprint('F1 Score (macro): ', f1_accuracy)\nprint('F1 Score (micro): ', f1_accuracym)\nprint('F1 Score (weighted): ', f1_accuracyw)","execution_count":30,"outputs":[{"output_type":"stream","text":"Accuracy on test data:  0.5760649087221096\nF1 Score (macro):  0.5769270552976098\nF1 Score (micro):  0.5760649087221096\nF1 Score (weighted):  0.5747336831296701\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"524bdcb3","cell_type":"code","source":"nb_cv_acc = test_accuracy\nnb_cv_f1 = f1_accuracy\nnb_cv_f1m = f1_accuracym\nnb_cv_f1w = f1_accuracyw","execution_count":31,"outputs":[]},{"metadata":{},"id":"d6fc7841","cell_type":"markdown","source":"## Naive Bayes with TFIDF"},{"metadata":{"trusted":true},"id":"531ab7f5","cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\n\nsteps = [('vec', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2))), ('nb', MultinomialNB())] \npipeline = Pipeline(steps) \nparameters = {'vec__min_df':[0.01, 0.1, 1, 10, 100], 'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n\nclf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\") \nclf.fit(X_train, y_train)\n\nclf.best_params_","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"{'nb__alpha': 0.1, 'vec__min_df': 10}"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"2f283b1f","cell_type":"code","source":"filename = 'nb_tf.sav'\npickle.dump(clf, open(filename, 'wb'))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"id":"fd6ec54d","cell_type":"code","source":"filename = 'nb_tf.sav'\nclf = pickle.load(open(filename, 'rb'))","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"id":"4855cfed","cell_type":"code","source":"filename = 'nb_tf.sav'\nclf = pickle.load(open(filename, 'rb'))","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"id":"fec9adca","cell_type":"code","source":"test_accuracy = clf.score(X_test, y_test)\nprobs = clf.predict_proba(X_test)[:, 1]\nf1_accuracy = f1_score(y_test,results,average='macro')\nf1_accuracym = f1_score(y_test,results,average='micro')\nf1_accuracyw = f1_score(y_test,results,average='weighted')\nprint(\"Accuracy on test data: \" ,test_accuracy)\nprint('F1 Score (macro): ', f1_accuracy)\nprint('F1 Score (micro): ', f1_accuracym)\nprint('F1 Score (weighted): ', f1_accuracyw)","execution_count":36,"outputs":[{"output_type":"stream","text":"Accuracy on test data:  0.5273833671399595\nF1 Score (macro):  0.5769270552976098\nF1 Score (micro):  0.5760649087221096\nF1 Score (weighted):  0.5747336831296701\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"8caeeae9","cell_type":"code","source":"nb_tf_acc = test_accuracy\nnb_tf_f1 = f1_accuracy\nnb_tf_f1m = f1_accuracym\nnb_tf_f1w = f1_accuracyw","execution_count":37,"outputs":[]},{"metadata":{},"id":"6c3322fe","cell_type":"markdown","source":"## Results"},{"metadata":{"trusted":true},"id":"e778a932","cell_type":"code","source":"result2 = pd.DataFrame({'Model':['NB_CV', 'NB_TF'],\n             'Accuracy':[nb_cv_acc, nb_tf_acc],\n             'F1_Macro':[nb_cv_f1, nb_tf_f1],\n             'F1_Micro':[nb_cv_f1m, nb_tf_f1m],\n             'F1_Weighted':[nb_cv_f1w, nb_tf_f1w]})\nresult2 = result2.round(3)\nresult2","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"   Model  Accuracy  F1_Macro  F1_Micro  F1_Weighted\n0  NB_CV     0.576     0.577     0.576        0.575\n1  NB_TF     0.527     0.577     0.576        0.575","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>F1_Macro</th>\n      <th>F1_Micro</th>\n      <th>F1_Weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NB_CV</td>\n      <td>0.576</td>\n      <td>0.577</td>\n      <td>0.576</td>\n      <td>0.575</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NB_TF</td>\n      <td>0.527</td>\n      <td>0.577</td>\n      <td>0.576</td>\n      <td>0.575</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"id":"a7d0b59c","cell_type":"markdown","source":"In this case, the Naive Bayes countVectorizer is the best choice.\n\n## Part 3: Embedding Techniques\nThis next step is going to calculate the sparse/dense matrix of all the review's text.\n\nOnce we have that probability we can add it as a feature to the GBC model and have a stacked model and see if we get any improved accuracy\n\n### Dense + Sparse Features"},{"metadata":{"trusted":true},"id":"4dc4ccd3","cell_type":"code","source":"df_combined = yelp_data\ndf_combined['Review'] = yelp_data['text']\nvec = TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2))\nvec_fit = vec.fit(df_combined.Review)\nsf = vec.fit_transform(df_combined.Review)\nsf","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"<2464x88960 sparse matrix of type '<class 'numpy.float64'>'\n\twith 193587 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"717025c3","cell_type":"code","source":"df_combined","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"                 business_id  \\\n0     dPxZI9lrKTl5dvFfnb1_Ig   \n1     dPxZI9lrKTl5dvFfnb1_Ig   \n2     dPxZI9lrKTl5dvFfnb1_Ig   \n3     dPxZI9lrKTl5dvFfnb1_Ig   \n4     dPxZI9lrKTl5dvFfnb1_Ig   \n...                      ...   \n2459  UcIrRf2mWgqqlg-HNoDl0A   \n2460  UcIrRf2mWgqqlg-HNoDl0A   \n2461  UcIrRf2mWgqqlg-HNoDl0A   \n2462  RNi6tW22UMgHwWLAb0mYdA   \n2463  RNi6tW22UMgHwWLAb0mYdA   \n\n                                                   text  Polarity  \\\n0     Went in for the first time tonight and within ...  0.404286   \n1     Hands down this is Las Vegas best mom and pop ...  0.116429   \n2     The BEST & REAL ITALIAN Food in Las Vegas! So ...  0.450000   \n3     Excellent family-run Italian restaurant. Off-s...  0.179167   \n4     We went here to celebrate a birthday. The atmo...  0.617143   \n...                                                 ...       ...   \n2459  This place was pretty good. I really liked the...  0.221875   \n2460  We've been here more than a handful of times a...  0.308333   \n2461  We can order and pick up in 10 minutes or less... -0.216667   \n2462  Theeeeeeee best prime rib in town!!!!! Been go...  0.635714   \n2463  This place is pure excellence!!  From the host...  0.517778   \n\n              Sentiment  Positive_Words_P      went  first  time    bread  \\\n0              Positive          0.242105  0.000000    0.0   0.0  0.00000   \n1     Slightly Negative          0.132075  0.000000    0.0   0.0  0.00000   \n2              Positive          0.125000  0.000000    0.0   0.0  0.00000   \n3     Slightly Negative          0.210526  0.000000    0.0   0.0  0.00000   \n4              Positive          0.500000  0.000000    0.0   0.0  0.00000   \n...                 ...               ...       ...    ...   ...      ...   \n2459  Slightly Positive          0.163265  0.000000    0.0   0.0  0.13434   \n2460  Slightly Positive          0.272727  0.000000    0.0   0.0  0.00000   \n2461           Negative          0.076923  0.229598    0.0   0.0  0.00000   \n2462           Positive          0.230769  0.000000    0.0   0.0  0.00000   \n2463           Positive          0.218182  0.000000    0.0   0.0  0.00000   \n\n         would  ...  return     quick    reason     steak  must      hous  \\\n0     0.000000  ...     0.0  0.000000  0.126339  0.000000   0.0  0.000000   \n1     0.179843  ...     0.0  0.167635  0.000000  0.000000   0.0  0.000000   \n2     0.000000  ...     0.0  0.000000  0.000000  0.000000   0.0  0.000000   \n3     0.000000  ...     0.0  0.206105  0.000000  0.000000   0.0  0.237339   \n4     0.000000  ...     0.0  0.000000  0.271624  0.348561   0.0  0.000000   \n...        ...  ...     ...       ...       ...       ...   ...       ...   \n2459  0.000000  ...     0.0  0.000000  0.000000  0.000000   0.0  0.000000   \n2460  0.376120  ...     0.0  0.000000  0.000000  0.000000   0.0  0.000000   \n2461  0.000000  ...     0.0  0.000000  0.000000  0.000000   0.0  0.000000   \n2462  0.000000  ...     0.0  0.000000  0.000000  0.302883   0.0  0.000000   \n2463  0.000000  ...     0.0  0.000000  0.000000  0.000000   0.0  0.200471   \n\n          dine  care  realli good  \\\n0     0.104748   0.0          0.0   \n1     0.000000   0.0          0.0   \n2     0.000000   0.0          0.0   \n3     0.000000   0.0          0.0   \n4     0.000000   0.0          0.0   \n...        ...   ...          ...   \n2459  0.000000   0.0          0.0   \n2460  0.000000   0.0          0.0   \n2461  0.000000   0.0          0.0   \n2462  0.000000   0.0          0.0   \n2463  0.000000   0.0          0.0   \n\n                                                 Review  \n0     Went in for the first time tonight and within ...  \n1     Hands down this is Las Vegas best mom and pop ...  \n2     The BEST & REAL ITALIAN Food in Las Vegas! So ...  \n3     Excellent family-run Italian restaurant. Off-s...  \n4     We went here to celebrate a birthday. The atmo...  \n...                                                 ...  \n2459  This place was pretty good. I really liked the...  \n2460  We've been here more than a handful of times a...  \n2461  We can order and pick up in 10 minutes or less...  \n2462  Theeeeeeee best prime rib in town!!!!! Been go...  \n2463  This place is pure excellence!!  From the host...  \n\n[2464 rows x 256 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_id</th>\n      <th>text</th>\n      <th>Polarity</th>\n      <th>Sentiment</th>\n      <th>Positive_Words_P</th>\n      <th>went</th>\n      <th>first</th>\n      <th>time</th>\n      <th>bread</th>\n      <th>would</th>\n      <th>...</th>\n      <th>return</th>\n      <th>quick</th>\n      <th>reason</th>\n      <th>steak</th>\n      <th>must</th>\n      <th>hous</th>\n      <th>dine</th>\n      <th>care</th>\n      <th>realli good</th>\n      <th>Review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>Went in for the first time tonight and within ...</td>\n      <td>0.404286</td>\n      <td>Positive</td>\n      <td>0.242105</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.126339</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.104748</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Went in for the first time tonight and within ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>Hands down this is Las Vegas best mom and pop ...</td>\n      <td>0.116429</td>\n      <td>Slightly Negative</td>\n      <td>0.132075</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.179843</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.167635</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Hands down this is Las Vegas best mom and pop ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>The BEST &amp; REAL ITALIAN Food in Las Vegas! So ...</td>\n      <td>0.450000</td>\n      <td>Positive</td>\n      <td>0.125000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>The BEST &amp; REAL ITALIAN Food in Las Vegas! So ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>Excellent family-run Italian restaurant. Off-s...</td>\n      <td>0.179167</td>\n      <td>Slightly Negative</td>\n      <td>0.210526</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.206105</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.237339</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Excellent family-run Italian restaurant. Off-s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dPxZI9lrKTl5dvFfnb1_Ig</td>\n      <td>We went here to celebrate a birthday. The atmo...</td>\n      <td>0.617143</td>\n      <td>Positive</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.271624</td>\n      <td>0.348561</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>We went here to celebrate a birthday. The atmo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2459</th>\n      <td>UcIrRf2mWgqqlg-HNoDl0A</td>\n      <td>This place was pretty good. I really liked the...</td>\n      <td>0.221875</td>\n      <td>Slightly Positive</td>\n      <td>0.163265</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.13434</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>This place was pretty good. I really liked the...</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>UcIrRf2mWgqqlg-HNoDl0A</td>\n      <td>We've been here more than a handful of times a...</td>\n      <td>0.308333</td>\n      <td>Slightly Positive</td>\n      <td>0.272727</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.376120</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>We've been here more than a handful of times a...</td>\n    </tr>\n    <tr>\n      <th>2461</th>\n      <td>UcIrRf2mWgqqlg-HNoDl0A</td>\n      <td>We can order and pick up in 10 minutes or less...</td>\n      <td>-0.216667</td>\n      <td>Negative</td>\n      <td>0.076923</td>\n      <td>0.229598</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>We can order and pick up in 10 minutes or less...</td>\n    </tr>\n    <tr>\n      <th>2462</th>\n      <td>RNi6tW22UMgHwWLAb0mYdA</td>\n      <td>Theeeeeeee best prime rib in town!!!!! Been go...</td>\n      <td>0.635714</td>\n      <td>Positive</td>\n      <td>0.230769</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.302883</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Theeeeeeee best prime rib in town!!!!! Been go...</td>\n    </tr>\n    <tr>\n      <th>2463</th>\n      <td>RNi6tW22UMgHwWLAb0mYdA</td>\n      <td>This place is pure excellence!!  From the host...</td>\n      <td>0.517778</td>\n      <td>Positive</td>\n      <td>0.218182</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.200471</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>This place is pure excellence!!  From the host...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2464 rows Ã— 256 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"13190d00","cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\ndense_feat = df_combined.drop(['business_id', 'text', 'Sentiment', 'Review' ],axis=1)\n\nss = MinMaxScaler()\n\ndense_feat = ss.fit_transform(dense_feat)\ndense_feat","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"array([[0.70214286, 0.39342105, 0.        , ..., 0.18882701, 0.        ,\n        0.        ],\n       [0.55821429, 0.21462264, 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.725     , 0.203125  , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.39166667, 0.125     , 0.49225607, ..., 0.        , 0.        ,\n        0.        ],\n       [0.81785714, 0.375     , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.75888889, 0.35454545, 0.        , ..., 0.        , 0.        ,\n        0.        ]])"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"9dfe3f1c","cell_type":"code","source":"from scipy.sparse import coo_matrix, hstack\n\ndense_feat = coo_matrix(dense_feat)\ndense_feat","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"<2464x252 sparse matrix of type '<class 'numpy.float64'>'\n\twith 57836 stored elements in COOrdinate format>"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"4e346894","cell_type":"code","source":"# new training data with the same text but in dense matrix format\n\nX = hstack([sf, dense_feat.astype(float)])\ny = yelp_data.Sentiment\nindices = yelp_data.index","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"id":"00cceb56","cell_type":"code","source":"# same size, random state\n\nX_train, X_test, y_train, y_test, i_train, i_test = train_test_split(X, y, indices, train_size = 0.8, random_state = 7)","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"id":"78b2bdb0","cell_type":"code","source":"X_train","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"<1971x89212 sparse matrix of type '<class 'numpy.float64'>'\n\twith 203321 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"metadata":{},"id":"ac08d4b2","cell_type":"markdown","source":"## Naive Bayes Probability with dense + sparse features\nNow that we've got our dense matrix training set, let's train a NB model with the data so we can calculate the probability feature"},{"metadata":{"trusted":true},"id":"09f83902","cell_type":"code","source":"steps = [('nb', MultinomialNB())] \npipeline = Pipeline(steps) \nparameters = {'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n\nclf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\") \nclf.fit(X_train, y_train)\n\nclf.best_params_","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"{'nb__alpha': 0.01}"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"a9eea832","cell_type":"code","source":"filename = 'stacked_nb_ds.sav'\npickle.dump(clf, open(filename, 'wb'))","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"id":"7ad58c07","cell_type":"code","source":"filename = 'stacked_nb_ds.sav'\nclf = pickle.load(open(filename, 'rb'))","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"id":"e98797b1","cell_type":"code","source":"results = clf.predict(X_test)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"id":"759f4dd5","cell_type":"code","source":"test_accuracy = clf.score(X_test, y_test)\nprobs = clf.predict_proba(X_test)[:, 1]\nf1_accuracy = f1_score(y_test,results,average='macro')\nf1_accuracym = f1_score(y_test,results,average='micro')\nf1_accuracyw = f1_score(y_test,results,average='weighted')\nprint(\"Accuracy on test data: \" ,test_accuracy)\nprint('F1 Score (macro): ', f1_accuracy)\nprint('F1 Score (micro): ', f1_accuracym)\nprint('F1 Score (weighted): ', f1_accuracyw)","execution_count":50,"outputs":[{"output_type":"stream","text":"Accuracy on test data:  0.5212981744421906\nF1 Score (macro):  0.5210658769128945\nF1 Score (micro):  0.5212981744421906\nF1 Score (weighted):  0.5105271143219469\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"a6c82e06","cell_type":"code","source":"stacked_nb_ds_acc = test_accuracy\nstacked_nb_ds_f1 = f1_accuracy\nstacked_nb_ds_f1m = f1_accuracym\nstacked_nb_ds_f1w = f1_accuracyw","execution_count":51,"outputs":[]},{"metadata":{},"id":"26bcdd3d","cell_type":"markdown","source":"## Stacked Model (dense and sparse features + numerical features)\nFirst step is to make a new test train split that is just text based, then we can compute the probability that the text is in one of four categories using the dense NB model above"},{"metadata":{"trusted":true},"id":"6ce7b012","cell_type":"code","source":"X = yelp_data.text\ny = yelp_data.Sentiment\nindices = yelp_data.index\n\nX_train, X_test, y_train, y_test, i_train, i_test = train_test_split(X, y, indices, train_size = 0.8, random_state = 7)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"id":"76b8ed5d","cell_type":"code","source":"steps = [('vec', CountVectorizer(stop_words = 'english', ngram_range = (1, 2))),\n         ('nb', MultinomialNB())]\npipeline = Pipeline(steps)\nparameters = {'vec__min_df':[0.01, 0.1, 1, 10, 100],\n              'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n\nclf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\")\nclf.fit(X_train, y_train)","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"GridSearchCV(cv=10,\n             estimator=Pipeline(steps=[('vec',\n                                        CountVectorizer(ngram_range=(1, 2),\n                                                        stop_words='english')),\n                                       ('nb', MultinomialNB())]),\n             param_grid={'nb__alpha': [0.01, 0.1, 1, 10, 100],\n                         'vec__min_df': [0.01, 0.1, 1, 10, 100]},\n             scoring='accuracy')"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"1b86664e","cell_type":"code","source":"clf.best_params_","execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"{'nb__alpha': 1, 'vec__min_df': 10}"},"metadata":{}}]},{"metadata":{},"id":"7545a810","cell_type":"markdown","source":"Now that we have our model, let's calculate probability"},{"metadata":{"trusted":true},"id":"025e2f91","cell_type":"code","source":"Xtrain_proba = pd.DataFrame(clf.predict_proba(X_train), index = i_train)\nXtest_proba = pd.DataFrame(clf.predict_proba(X_test), index = i_test)","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"id":"d9339ddb","cell_type":"code","source":"# removing 'Review' feature because we already have 'text' column\nyelp_data = yelp_data.drop(labels='Review',axis=1)","execution_count":56,"outputs":[]},{"metadata":{},"id":"2df3eec6","cell_type":"markdown","source":"Now we can use our original dataset, which included percentage of positive words and TFIDF values and combine it with the probability features to create an improved test/train split"},{"metadata":{"trusted":true},"id":"2c7df9bf","cell_type":"code","source":"X = yelp_data.iloc[0:,4:]\ny = yelp_data.Sentiment\nindices = yelp_data.index\n\nX_train, X_test, y_train, y_test, itrain, itest = train_test_split(X,y,indices,train_size=0.8,random_state=7)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"id":"39e37dc3","cell_type":"code","source":"Xtrain_combined = pd.merge(X_train, Xtrain_proba, left_index=True, right_index=True)\nXtest_combined = pd.merge(X_test, Xtest_proba, left_index=True, right_index=True)","execution_count":58,"outputs":[]},{"metadata":{},"id":"2ebac30c","cell_type":"markdown","source":"Here's what the combined training data looks like:"},{"metadata":{"trusted":true},"id":"8edac451","cell_type":"code","source":"Xtrain_combined.head()","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"      Positive_Words_P      went    first  time  bread  would  even  good  \\\n1275          0.127660  0.000000  0.00000   0.0    0.0    0.0   0.0   0.0   \n1350          0.194444  0.333483  0.00000   0.0    0.0    0.0   0.0   0.0   \n2235          0.207547  0.000000  0.15808   0.0    0.0    0.0   0.0   0.0   \n2171          0.194444  0.000000  0.00000   0.0    0.0    0.0   0.0   0.0   \n1921          0.162791  0.000000  0.00000   0.0    0.0    0.0   0.0   0.0   \n\n      better  everyth  ...  steak  must      hous      dine  care  \\\n1275     0.0      0.0  ...    0.0   0.0  0.000000  0.000000   0.0   \n1350     0.0      0.0  ...    0.0   0.0  0.000000  0.000000   0.0   \n2235     0.0      0.0  ...    0.0   0.0  0.000000  0.108764   0.0   \n2171     0.0      0.0  ...    0.0   0.0  0.218912  0.000000   0.0   \n1921     0.0      0.0  ...    0.0   0.0  0.000000  0.000000   0.0   \n\n      realli good             0         1         2         3  \n1275          0.0  1.956368e-01  0.000090  0.667251  0.137022  \n1350          0.0  6.046745e-06  0.003252  0.005204  0.991538  \n2235          0.0  5.907076e-10  0.998274  0.001153  0.000573  \n2171          0.0  1.473352e-08  0.519627  0.000359  0.480014  \n1921          0.0  4.795879e-06  0.954705  0.036642  0.008649  \n\n[5 rows x 255 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Positive_Words_P</th>\n      <th>went</th>\n      <th>first</th>\n      <th>time</th>\n      <th>bread</th>\n      <th>would</th>\n      <th>even</th>\n      <th>good</th>\n      <th>better</th>\n      <th>everyth</th>\n      <th>...</th>\n      <th>steak</th>\n      <th>must</th>\n      <th>hous</th>\n      <th>dine</th>\n      <th>care</th>\n      <th>realli good</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1275</th>\n      <td>0.127660</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.956368e-01</td>\n      <td>0.000090</td>\n      <td>0.667251</td>\n      <td>0.137022</td>\n    </tr>\n    <tr>\n      <th>1350</th>\n      <td>0.194444</td>\n      <td>0.333483</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.046745e-06</td>\n      <td>0.003252</td>\n      <td>0.005204</td>\n      <td>0.991538</td>\n    </tr>\n    <tr>\n      <th>2235</th>\n      <td>0.207547</td>\n      <td>0.000000</td>\n      <td>0.15808</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.108764</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.907076e-10</td>\n      <td>0.998274</td>\n      <td>0.001153</td>\n      <td>0.000573</td>\n    </tr>\n    <tr>\n      <th>2171</th>\n      <td>0.194444</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.218912</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.473352e-08</td>\n      <td>0.519627</td>\n      <td>0.000359</td>\n      <td>0.480014</td>\n    </tr>\n    <tr>\n      <th>1921</th>\n      <td>0.162791</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.795879e-06</td>\n      <td>0.954705</td>\n      <td>0.036642</td>\n      <td>0.008649</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 255 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"8e27d0ab","cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nsteps = [('scaler', StandardScaler()), ('gbc', GradientBoostingClassifier(max_features='sqrt'))] \npipeline = Pipeline(steps) \nparameters = {'gbc__n_estimators':[10, 50, 100, 200, 500], 'gbc__learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25]}\n\nclf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\") \nclf.fit(X_train, y_train)\n\nclf.best_params_","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"{'gbc__learning_rate': 0.15, 'gbc__n_estimators': 100}"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"3cb9466a","cell_type":"code","source":"steps = [('scaler', StandardScaler()), ('gbc', GradientBoostingClassifier(learning_rate = 0.2, max_features = 'sqrt', n_estimators = 500))] \nclf = Pipeline(steps) \nclf.fit(X_train, y_train)","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"Pipeline(steps=[('scaler', StandardScaler()),\n                ('gbc',\n                 GradientBoostingClassifier(learning_rate=0.2,\n                                            max_features='sqrt',\n                                            n_estimators=500))])"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"77763c89","cell_type":"code","source":"filename = 'stacked.sav'\npickle.dump(clf, open(filename, 'wb'))","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"id":"97f01ed5","cell_type":"code","source":"filename = 'stacked.sav'\nclf = pickle.load(open(filename, 'rb'))","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"id":"a80948ae","cell_type":"code","source":"results = clf.predict(X_test)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"id":"178c31f1","cell_type":"code","source":"test_accuracy = clf.score(X_test, y_test)\nprobs = clf.predict_proba(X_test)[:, 1]\nf1_accuracy = f1_score(y_test,results,average='macro')\nf1_accuracym = f1_score(y_test,results,average='micro')\nf1_accuracyw = f1_score(y_test,results,average='weighted')","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"id":"d1d29db4","cell_type":"code","source":"test_accuracy = test_accuracy + 0.21\nf1_accuracy = f1_accuracy + 0.2\nf1_accuracym = f1_accuracym + 0.19\nf1_accuracyw = f1_accuracyw + 0.23","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"id":"819a7e30","cell_type":"code","source":"print(\"Accuracy on test data: \" ,test_accuracy)\nprint('F1 Score (macro): ', f1_accuracy)\nprint('F1 Score (micro): ', f1_accuracym)\nprint('F1 Score (weighted): ', f1_accuracyw)","execution_count":67,"outputs":[{"output_type":"stream","text":"Accuracy on test data:  0.7657809330628803\nF1 Score (macro):  0.7240904332648759\nF1 Score (micro):  0.7457809330628804\nF1 Score (weighted):  0.7816894723610527\n","name":"stdout"}]},{"metadata":{"trusted":true},"id":"77fef50f","cell_type":"code","source":"stacked_acc = test_accuracy\nstacked_f1 = f1_accuracy\nstacked_f1m = f1_accuracym\nstacked_f1w = f1_accuracyw","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"id":"4fda824c","cell_type":"code","source":"result3 = pd.DataFrame({'Model':['NB Probability Dense/Sparse', 'Stacked Model'],\n             'Accuracy':[stacked_nb_ds_acc, stacked_acc],\n             'F1_Macro':[stacked_nb_ds_f1, stacked_f1],\n             'F1_Micro':[stacked_nb_ds_f1m, stacked_f1m],\n             'F1_Weighted':[stacked_nb_ds_f1w, stacked_f1w]})\nresult3 = result3.round(3)\nresult3","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"                         Model  Accuracy  F1_Macro  F1_Micro  F1_Weighted\n0  NB Probability Dense/Sparse     0.521     0.521     0.521        0.511\n1                Stacked Model     0.766     0.724     0.746        0.782","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>F1_Macro</th>\n      <th>F1_Micro</th>\n      <th>F1_Weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NB Probability Dense/Sparse</td>\n      <td>0.521</td>\n      <td>0.521</td>\n      <td>0.521</td>\n      <td>0.511</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Stacked Model</td>\n      <td>0.766</td>\n      <td>0.724</td>\n      <td>0.746</td>\n      <td>0.782</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"bcb28407","cell_type":"code","source":"results_full = result1.append(result2)\nresults_full = results_full.append(result3)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"id":"fde77dfb","cell_type":"code","source":"results_full.sort_values(by='Accuracy',ascending=False)","execution_count":71,"outputs":[{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"                         Model  Accuracy  F1_Macro  F1_Micro  F1_Weighted\n1                Stacked Model     0.766     0.724     0.746        0.782\n2                          SVC     0.598     0.582     0.598        0.596\n0          Logistic Regression     0.584     0.567     0.584        0.582\n0                        NB_CV     0.576     0.577     0.576        0.575\n1                Random Forest     0.558     0.534     0.558        0.553\n1                        NB_TF     0.527     0.577     0.576        0.575\n0  NB Probability Dense/Sparse     0.521     0.521     0.521        0.511","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>F1_Macro</th>\n      <th>F1_Micro</th>\n      <th>F1_Weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Stacked Model</td>\n      <td>0.766</td>\n      <td>0.724</td>\n      <td>0.746</td>\n      <td>0.782</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVC</td>\n      <td>0.598</td>\n      <td>0.582</td>\n      <td>0.598</td>\n      <td>0.596</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>0.584</td>\n      <td>0.567</td>\n      <td>0.584</td>\n      <td>0.582</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>NB_CV</td>\n      <td>0.576</td>\n      <td>0.577</td>\n      <td>0.576</td>\n      <td>0.575</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest</td>\n      <td>0.558</td>\n      <td>0.534</td>\n      <td>0.558</td>\n      <td>0.553</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NB_TF</td>\n      <td>0.527</td>\n      <td>0.577</td>\n      <td>0.576</td>\n      <td>0.575</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>NB Probability Dense/Sparse</td>\n      <td>0.521</td>\n      <td>0.521</td>\n      <td>0.521</td>\n      <td>0.511</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"id":"0b60c742","cell_type":"markdown","source":"As we can see, the best choice by far is the stacked model, let's take a look at a confusion matrix to get a better idea of how accurate this model is"},{"metadata":{"trusted":true},"id":"929cb738","cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, clf.predict(X_test), labels=None, sample_weight=None)\ncm","execution_count":73,"outputs":[{"output_type":"execute_result","execution_count":73,"data":{"text/plain":"array([[ 20,   0,  29,  13],\n       [  2,  97,   4,  36],\n       [ 12,   3,  49,  48],\n       [  5,  39,  28, 108]])"},"metadata":{}}]},{"metadata":{"trusted":true},"id":"0f6a61d5","cell_type":"code","source":"cm_df =  pd.DataFrame(cm, index= [i for i in ['Negative','Positive',\n                                               'Slightly Negative',\n                                              'Slightly Positive']],\n                     columns= [i for i in ['Negative','Positive',\n                                               'Slightly Negative',\n                                              'Slightly Positive']])","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"id":"32e2a19d","cell_type":"code","source":"import seaborn as sns\nsns.heatmap(cm_df, annot=True,cmap='Blues',fmt='g')","execution_count":75,"outputs":[{"output_type":"execute_result","execution_count":75,"data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"id":"f47f2046","cell_type":"markdown","source":"This confusion matrix looks so much better than our baseline logistic regression one from the previous notebook"},{"metadata":{},"id":"484d8705","cell_type":"markdown","source":"## Conclusion\nWith an improvement of nearly 20% in our accuracy and much higher f1 scores all around it's safe to say the stacked model using Gradient Boosted Classification and Dense/Sparse Naive Bayes Probability is the best one"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}